'''
åŠŸèƒ½ï¼šä½¿ç”¨ FinBERT æ¨¡å‹å¯¹æŠ“å–çš„æ–°é—»è¿›è¡Œæƒ…ç»ªåˆ†æ
è¾“å…¥ï¼šdata/raw ç›®å½•ä¸‹çš„æ–°é—»æ•°æ®ï¼ˆå¦‚ AAPL_news_15d_finnhub.csvï¼‰
è¾“å‡ºï¼šæ·»åŠ æƒ…ç»ªæ ‡ç­¾å’Œç½®ä¿¡åº¦çš„ DataFrameï¼Œä¿å­˜ä¸º sentiment CSV æ–‡ä»¶
'''

import os
import pandas as pd
from transformers import BertTokenizer, BertForSequenceClassification
import torch
from tqdm import tqdm

# åŠ è½½ FinBERT æ¨¡å‹
tokenizer = BertTokenizer.from_pretrained('ProsusAI/finbert')
model = BertForSequenceClassification.from_pretrained('ProsusAI/finbert')

# é¢„æµ‹å•æ¡æ–‡æœ¬çš„æƒ…ç»ª
def classify_sentiment(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
    probs = torch.nn.functional.softmax(outputs.logits, dim=1)
    confidence, prediction = torch.max(probs, dim=1)
    label_map = {0: 'negative', 1: 'neutral', 2: 'positive'}
    return label_map[prediction.item()], round(confidence.item(), 4)

# åˆ†ææ•´ä¸ªæ–‡ä»¶
def analyze_sentiment_for_file(filepath):
    df = pd.read_csv(filepath)

    if 'headline' not in df.columns:
        raise ValueError(f"'headline' column not found in {filepath}")

    sentiments = []
    confidences = []

    print(f"ğŸ“Š Analyzing sentiment for: {os.path.basename(filepath)}")

    for text in tqdm(df['headline']):
        label, conf = classify_sentiment(str(text))
        sentiments.append(label)
        confidences.append(conf)

    df['sentiment'] = sentiments
    df['confidence'] = confidences

    return df

# è¿è¡Œåˆ†æä»»åŠ¡
def run_sentiment_analysis():
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
    input_folder = os.path.join(project_root, "data", "raw")
    output_folder = os.path.join(project_root, "data", "processed")
    os.makedirs(output_folder, exist_ok=True)

    # è·å–å·²å¤„ç†æ–‡ä»¶åï¼ˆå»æ‰åç¼€ï¼‰
    processed_files = {
        f.replace('_sentiment.csv', '') for f in os.listdir(output_folder) if f.endswith('_sentiment.csv')
    }

    for filename in os.listdir(input_folder):
        if filename.endswith('.csv') and 'finnhub' in filename:
            base_name = filename.replace('.csv', '')
            if base_name in processed_files:
                print(f"â­ï¸ Skipping already processed: {filename}")
                continue

            filepath = os.path.join(input_folder, filename)
            df = analyze_sentiment_for_file(filepath)

            output_file = filename.replace('.csv', '_sentiment.csv')
            df.to_csv(os.path.join(output_folder, output_file), index=False)
            print(f"âœ… Saved: {output_file}")


if __name__ == "__main__":
    run_sentiment_analysis()
